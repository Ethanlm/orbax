{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZJ9ep0O3S0m"
      },
      "source": [
        "# Exporting with Orbax\n",
        "\n",
        "Orbax Export is a library for exporting JAX models to TensorFlow\n",
        "[SavedModel](https://www.tensorflow.org/guide/saved_model) format.\n",
        "\n",
        "## Exporting\n",
        "\n",
        "### API Overview\n",
        "\n",
        "Orbax Export provides three classes.\n",
        "\n",
        "-   `JaxModule`\n",
        "    wraps a JAX function and its parameters to an exportable and callable\n",
        "    closure.\n",
        "-   `ServingConfig`\n",
        "    defines a serving configuration for a `JaxModule`, including\n",
        "    [a signature key and an input signature][1], and optionally pre- and\n",
        "    post-processing functions and extra [TrackableResources][2].\n",
        "-   `ExportManager`\n",
        "    builds the actual [serving signatures][1] based on a `JaxModule` and a list\n",
        "    of `ServingConfig`s, and saves them to the SavedModel format. It is for CPU.\n",
        "    Users can inherit `ExportManager` class and create their own \"ExportManager\"\n",
        "    for different hardwares.\n",
        "\n",
        "### Simple Example Usage\n",
        "\n",
        "#### Setup\n",
        "\n",
        "```\n",
        "# Import Orbax Export classes.\n",
        "from orbax.export import ExportManager\n",
        "from orbax.export import JaxModule\n",
        "from orbax.export import ServingConfig\n",
        "\n",
        "# Prepare the parameters and model function to export.\n",
        "params = ... # A pytree of the JAX model parameters.\n",
        "\n",
        "def model_fn(params, inputs):  # The JAX model function to export.\n",
        "  ...\n",
        "\n",
        "def preprocess(*inputs):  # Optional: preprocessor in TF.\n",
        "  ...\n",
        "\n",
        "def postprocess(model_fn_outputs):  # Optional: post-processor in TF.\n",
        "  ...\n",
        "```\n",
        "\n",
        "#### Exporting a JAX model to a CPU SavedModel\n",
        "\n",
        "```\n",
        "# Construct a JaxModule where JAX-\u003eTF conversion happens.\n",
        "jax_module = JaxModule(params, model_fn)\n",
        "# Export the JaxModule along with one or more serving configs.\n",
        "export_mgr = ExportManager(\n",
        "  jax_module, [\n",
        "    ServingConfig(\n",
        "      'serving_default',\n",
        "      input_signature=[tf.TensorSpec(...)],\n",
        "      tf_preprocessor=preprocess,\n",
        "      tf_postprocessor=postprocess\n",
        "    ),\n",
        "])\n",
        "export_mgr.save(output_dir)\n",
        "```\n",
        "\n",
        "### Known issues\n",
        "\n",
        "## Error message \"JaxModule only take single arg as the input\".\n",
        "\n",
        "Orbax is designed to take a JAX Module in the format of a Callable with\n",
        "parameters of type PyTree and model inputs of type PyTree. If your JAX function\n",
        "takes multiple inputs, you must pack them into a single JAX PyTree. Otherwise,\n",
        "you will encounter this error message.\n",
        "\n",
        "To solve this problem, you can update the `ServingConfig.tf_preprocessor`\n",
        "function to pack the inputs into a single JAX PyTree. For example, our model\n",
        "takes two inputs `x` and `y`. You can define the `ServingConfig.tf_preprocessor`\n",
        "pack them into a list `[x, y]`.\n",
        "\n",
        "```\n",
        "def tf_preprocessor(x, y):\n",
        "  # put the normal tf_preprocessor codes here.\n",
        "  return [x, y] # pack it into a single list for jax model_func.\n",
        "\n",
        "jax_module = orbax.export.JaxModule(params, model_func)\n",
        "export_mgr = orbax.export.ExportManager(\n",
        "  jax_module,\n",
        "  [\n",
        "      orbax.export.ServingConfig(\n",
        "          'serving_default',\n",
        "          input_signature=[tf.TensorSpec([16]), tf.TensorSpec([16])],\n",
        "          tf_preprocessor=tf_preprocessor,\n",
        "      )\n",
        "  ],\n",
        ")\n",
        "export_mgr.save('/tmp/foo')\n",
        "```\n",
        "\n",
        "## Validating\n",
        "\n",
        "### API Overview\n",
        "\n",
        "Orbax.export.validate is library that can be used to validate the JAX model and\n",
        "its exported TF [SavedModel](https://www.tensorflow.org/guide/saved_model)\n",
        "format.\n",
        "\n",
        "Users must finish the JAX model exporting first. Users can export the model by\n",
        "orbax.export or manually.\n",
        "\n",
        "Orbax.export.validate provides those classes:\n",
        "\n",
        "*   `ValidationJob`\n",
        "    take the model and data as input, then output the result.\n",
        "*   `ValidationReport`\n",
        "    compare the JAX model and TF SavedModel results, then generate the formatted\n",
        "    report.\n",
        "*   `ValidationManager`\n",
        "    take `JaxModule` as inputs and wrap the validation e2e flow.\n",
        "\n",
        "### Simple Example Usage\n",
        "\n",
        "Here is a simple example.\n",
        "\n",
        "```\n",
        "from orbax.export.validate import ValidationManager\n",
        "from orbax.export import JaxModule\n",
        "from orbax.export import ServingConfig\n",
        "\n",
        "params = {'bias': jnp.array(1)}\n",
        "apply_fn = lambda params, inputs: inputs['x'] + params['bias']\n",
        "jax_module = JaxModule(params, apply_fn)\n",
        "batch_inputs = [{'x': np.arange(8).astype(np.int32)}] * 16\n",
        "\n",
        "serving_configs = [\n",
        "  ServingConfig(\n",
        "                  'serving_default',\n",
        "                  input_signature=[{\n",
        "                    'x': tf.TensorSpec((), tf.dtypes.int32, name='x')\n",
        "                    }],\n",
        "  ),\n",
        "]\n",
        "validation_mgr = ValidationManager(jax_module.jax_methods, serving_configs,\n",
        "                                       batch_inputs)\n",
        "\n",
        "tf_saved_model_path = ...\n",
        "loaded_model = tf.saved_model.load(tf_saved_model_path)\n",
        "# for tpu model:\n",
        "# loaded_model = tf.saved_model.load(tf_saved_model_path, tags=['serve', 'tpu'])\n",
        "validation_reports = validation_mgr.validate(loaded_model)\n",
        "```\n",
        "\n",
        "`validation_reports` is a python dict and the key is TF SavedModel serving_key.\n",
        "\n",
        "```\n",
        "for key in validation_reports:\n",
        "  self.assertEqual(validation_reports[key].status.name,'Pass')\n",
        "  # Users can also save the converted json to file.\n",
        "  json_str = validation_reports[key].to_json()\n",
        "```\n",
        "\n",
        "### Limitation\n",
        "\n",
        "Here we list those limitation of Orbax.export validate module.\n",
        "\n",
        "*   To avoid ambiguity, the model inputs must be a dictionary from string to\n",
        "    Tensor. The input signature TensorSpec name should be same as the key. This\n",
        "    is an example.\n",
        "\n",
        "```\n",
        "python image = random.normal(random.PRNGKey(1), (32, 28, 28, 1),\n",
        "dtype=jnp.float32) label = random.randint(random.PRNGKey(1), (32,), 0, 10,\n",
        "dtype=jnp.int64) mnist_inputs = {'image': image, 'label': label}\n",
        "\n",
        "mnist_input_signature = [ { 'image': TensorSpec(shape=(32, 28, 28, 1),\n",
        "dtype=tf.float32, name='image'), 'label': TensorSpec(shape=(32,),\n",
        "dtype=tf.int32, name='label') } ]\n",
        "```\n",
        "\n",
        "*   Because the TF SavedModel the returned object is always a map. If the jax\n",
        "    model output is a sequence, TF SavedModel will convert it to map. The tensor\n",
        "    names are fairly generic, like output_0. To help `ValidationReport` module\n",
        "    can do apple-to-apple comparison between JAX model and TF model result, we\n",
        "    suggest users modify the model output as a dictionary.\n",
        "\n",
        "## Examples\n",
        "\n",
        "Check-out the\n",
        "[examples](https://github.com/google/orbax/tree/main/export/orbax/export/examples)\n",
        "directory for a number of examples using Orbax Export.\n",
        "\n",
        "[1]: https://www.tensorflow.org/guide/saved_model#specifying_signatures_during_export\n",
        "[2]: https://www.tensorflow.org/api_docs/python/tf/saved_model/experimental/TrackableResource"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeMLn6B7R1pP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/grp/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "provenance": [
        {
          "file_id": "1QNxBBBN16Br9Xj-a7LvtJzJWjOBhjFps",
          "timestamp": 1686159333109
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

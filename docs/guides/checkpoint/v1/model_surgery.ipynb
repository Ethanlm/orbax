{
  "cells": [
    {
      "metadata": {
        "id": "wKwPYpX3QC-n"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Surgery"
      ]
    },
    {
      "metadata": {
        "id": "sE5cMQgVQNI4"
      },
      "cell_type": "markdown",
      "source": [
        "Oftentimes, the model we saved to disk isn't exactly the model we wish to work with in memory. Some examples of this are:\n",
        "\n",
        " - Stacking/unstacking layers to match your training setup\n",
        " - Fine-tuning a multi-modal model from multiple uni-modal models\n",
        " - Using a frozen teacher model at each iteration of the training loop for a student model\n",
        " - Loading only the weights section of the PyTree, and ignoring things like optimizer state, when doing model evaluation\n",
        "\n",
        "Model surgery is a toolset designed precisely for this kind of task.\n",
        "\n",
        "Orbax Checkpointing currently exposes a Partial Loading API, which allows for a subset of PyTree leaves (or, a \"strict subtree\") to be loaded from the full model on disk. More arbitrary manipulation of leaves and trees is planned to be added in the future, such as loading multiple trees and merging them into one.\n",
        "\n",
        "Let's first take a look at what it's like to restore part of a PyTree, then touch on the planned Advanced Model Surgery API."
      ]
    },
    {
      "metadata": {
        "id": "94YH4uw-NAKd"
      },
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import numpy as np\n",
        "from orbax.checkpoint import v1 as ocp\n",
        "from etils import epath\n",
        "\n",
        "path = epath.Path('/tmp/my-checkpoints/ckpt-1')\n",
        "pytree = {\n",
        "  'params': {\n",
        "    'layer0': {\n",
        "      'kernel': np.random.uniform(size=(2, 2)),\n",
        "      'bias': np.ones(2),\n",
        "    },\n",
        "  },\n",
        "  'opt_state': {\n",
        "    '0': np.random.random(size=(2,)),\n",
        "    '1': [np.ones(2), np.ones(2)],\n",
        "  },\n",
        "  'step': np.asarray(0),\n",
        "}\n",
        "mesh = jax.sharding.Mesh(jax.devices(), ('x',))\n",
        "sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec(None))\n",
        "pytree = jax.tree.map(\n",
        "    lambda arr: jax.make_array_from_callback(\n",
        "        arr.shape,\n",
        "        sharding,\n",
        "        lambda idx: arr[idx],\n",
        "    ),\n",
        "    pytree,\n",
        ")\n",
        "ocp.save_pytree(path, pytree, overwrite=True)"
      ],
      "outputs": [],
      "execution_count": 11
    },
    {
      "metadata": {
        "id": "zVDqy24bNAKe"
      },
      "cell_type": "markdown",
      "source": [
        "## Partial Loading"
      ]
    },
    {
      "metadata": {
        "id": "CnnAu7pVNAKe"
      },
      "cell_type": "markdown",
      "source": [
        "Partial loading is a way to solve the most common use case of loading a different tree than is present in the checkpoint - where leaves or subtrees can be omitted. The canonical example is to skip loading the optimizer state when you're doing evaluation. There are a couple of ways to do this with the Partial Loading API. Let's take a look at both."
      ]
    },
    {
      "metadata": {
        "id": "fxMiFWraNAKe"
      },
      "cell_type": "markdown",
      "source": [
        "### Placeholder"
      ]
    },
    {
      "metadata": {
        "id": "ARscwVOZNAKe"
      },
      "cell_type": "markdown",
      "source": [
        "Since we don't need the optimizer state (`opt_state`) during model evaluation, we can signal to Orbax to skip loading the leaves with that node by using the `ocp.PLACEHOLDER` (`...`) value."
      ]
    },
    {
      "metadata": {
        "id": "FMb-DDowNAKe"
      },
      "cell_type": "code",
      "source": [
        "abstract_tree = {\n",
        "  'params': {\n",
        "    'layer0': {\n",
        "      'kernel': np.array([]),\n",
        "      'bias': np.array([]),\n",
        "    },\n",
        "  },\n",
        "  # Skip loading 'opt_state'\n",
        "  'opt_state': {\n",
        "    '0': ...,\n",
        "    '1': [..., ...],\n",
        "  },\n",
        "  'step': np.array([]),\n",
        "}\n",
        "\n",
        "ocp.load_pytree(path, abstract_tree)"
      ],
      "outputs": [],
      "execution_count": 12
    },
    {
      "metadata": {
        "id": "oEmjmI5vNAKe"
      },
      "cell_type": "markdown",
      "source": [
        "Note that `ocp.PLACEHOLDER` can only be used for leaves, so `opt_state: ocp.PLACEHOLDER` would not work. Keeping the structure consistent in this way is important for use cases like merging the original state with the restored state."
      ]
    },
    {
      "metadata": {
        "id": "GHpi140UNAKe"
      },
      "cell_type": "code",
      "source": [
        "bad_abstract_tree = {\n",
        "  'params': {\n",
        "    'layer0': {\n",
        "      'kernel': np.array([]),\n",
        "      'bias': np.array([]),\n",
        "    },\n",
        "  },\n",
        "  # Skip loading 'opt_state'\n",
        "  'opt_state': ...,\n",
        "  'step': np.array([]),\n",
        "}\n",
        "\n",
        "try:\n",
        "  ocp.load_pytree(path, bad_abstract_tree)\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "outputs": [],
      "execution_count": 13
    },
    {
      "metadata": {
        "id": "MAPPk4mmNAKe"
      },
      "cell_type": "markdown",
      "source": [
        "Creating an abstract tree by hand is tedious. A more natural way to do this is by using something like JAX's `tree_map_with_path`."
      ]
    },
    {
      "metadata": {
        "id": "d9km3IL6NAKe"
      },
      "cell_type": "code",
      "source": [
        "def _create_abstract_leaf_for_partial_load(leaf_path, _):\n",
        "  leaf_path = jax.tree_util.keystr(leaf_path, simple=True, separator='/')\n",
        "  if (leaf_path.split('/')[0] == 'opt_state'):\n",
        "    return ocp.PLACEHOLDER \n",
        "  else:\n",
        "    return np.array([])\n",
        "\n",
        "easy_abstract_tree = jax.tree.map_with_path(\n",
        "  _create_abstract_leaf_for_partial_load,\n",
        "  pytree\n",
        ")\n",
        "\n",
        "ocp.load_pytree(path, easy_abstract_tree)"
      ],
      "outputs": [],
      "execution_count": 14
    },
    {
      "metadata": {
        "id": "5BlmcRrPNAKe"
      },
      "cell_type": "markdown",
      "source": [
        "We may not have direct access to the original PyTree when creating the abstract counterpart, and in that case, we'll need to use the on-disk `pytree_metadata`."
      ]
    },
    {
      "metadata": {
        "id": "c-8wzf_rNAKe"
      },
      "cell_type": "code",
      "source": [
        "on_disk_pytree_structure = ocp.pytree_metadata(path).metadata\n",
        "\n",
        "abstract_tree_from_metadata = jax.tree.map_with_path(\n",
        "  _create_abstract_leaf_for_partial_load,\n",
        "  on_disk_pytree_structure\n",
        ")\n",
        "\n",
        "ocp.load_pytree(path, abstract_tree_from_metadata)"
      ],
      "outputs": [],
      "execution_count": 15
    },
    {
      "metadata": {
        "id": "u5kKXsr1XjDq"
      },
      "cell_type": "markdown",
      "source": [
        "### Omission"
      ]
    },
    {
      "metadata": {
        "id": "k_J95vK-OIsj"
      },
      "cell_type": "markdown",
      "source": [
        "Alternatively, we can enable the `partial_load` option to avoid having to explicitly specify nodes to be skipped. Instead, we simply ignore those nodes during construction of the abstract PyTree."
      ]
    },
    {
      "metadata": {
        "id": "SiI0Eh6WOIFy"
      },
      "cell_type": "code",
      "source": [
        "abstract_tree = {\n",
        "  'params': {\n",
        "      'layer0': {\n",
        "        'kernel': np.array([]),\n",
        "        'bias': np.array([]),\n",
        "      },\n",
        "  },\n",
        "  # Note: omit 'opt_state' to avoid loading it\n",
        "  'step': 0,\n",
        "}\n",
        "\n",
        "# Loading PyTrees with certain leaves missing is unsafe\n",
        "try:\n",
        "  ocp.load_pytree(path, abstract_tree)\n",
        "except ValueError as e:\n",
        "  print(e)\n",
        "\n",
        "# So partial_load must be opted-into\n",
        "with ocp.Context(\n",
        "    pytree_options=ocp.options.PyTreeOptions(\n",
        "        loading=ocp.options.PyTreeOptions.Loading(\n",
        "            partial_load=True,\n",
        "        ),\n",
        "    ),\n",
        "):\n",
        "  ocp.load_pytree(path, abstract_tree)"
      ],
      "outputs": [],
      "execution_count": 16
    },
    {
      "metadata": {
        "id": "By5aAqe3w1kx"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Surgery\n",
        "\n",
        "While partial loading is useful for omitting parts of a PyTree, it does not allow for more complex manipulations. In contrast, the planned Model Surgery API is a powerful toolset where the user can manipulate trees and leaves in arbitrary ways. This includes restructuring trees, modifying values, and even loading and merging multiple distinct checkpoints into a single model in memory.\n",
        "\n",
        "The core of this API will be user-defined transformation functions that are applied to checkpoints during the loading process.\n",
        "\n",
        "#### Single-Model Transformations\n",
        "\n",
        "A common use case for model surgery is transforming a single checkpoint into a different structure. For example, you might want to stack model layers that were saved individually. This can be accomplished with a transform_fn that takes the PyTree from the source checkpoint and returns a new, modified PyTree.\n",
        "\n",
        "A potential API for this could look like:"
      ]
    },
    {
      "metadata": {
        "id": "_ZsfDUys54PH"
      },
      "cell_type": "code",
      "source": [
        "ocp.load_and_transform = lambda *args: None\n",
        "\n",
        "def stack_layers_transform(source_tree):\n",
        "  params = source_tree['params']\n",
        "  # Assumes layers are named 'layer0', 'layer1', etc.\n",
        "  layer_keys = sorted([k for k in params if 'layer' in k])\n",
        "  \n",
        "  stacked_layers = jax.numpy.stack([params[k]['kernel'] for k in layer_keys])\n",
        "  \n",
        "  new_params = {'stacked_layers': stacked_layers}\n",
        "  # Bring over any other parameters that are not part of the stacking.\n",
        "  for k in params:\n",
        "    if 'layer' not in k:\n",
        "      new_params[k] = params[k]\n",
        "      \n",
        "  source_tree['params'] = new_params\n",
        "  return source_tree\n",
        "\n",
        "abstract_tree = ...\n",
        "\n",
        "# The API would apply the transformation during loading.\n",
        "restored_tree = ocp.load_and_transform(path, stack_layers_transform, abstract_tree)"
      ],
      "outputs": [],
      "execution_count": 19
    },
    {
      "metadata": {
        "id": "-KGlbL1p5ej9"
      },
      "cell_type": "markdown",
      "source": [
        "#### Multi-Model Transformations\n",
        "\n",
        "A more advanced use case is merging multiple checkpoints. A key example is creating a multi-modal model by combining two separately trained uni-modal models (e.g., an image model and a text model).\n",
        "\n",
        "A transformation function for this scenario would accept multiple source trees and define how they should be combined."
      ]
    },
    {
      "metadata": {
        "id": "0tJdX4wQ6AKF"
      },
      "cell_type": "code",
      "source": [
        "def merge_models_transform(image_model_tree, text_model_tree):\n",
        "  return {\n",
        "      'params': {\n",
        "          'image_encoder': image_model_tree['params'],\n",
        "          'text_encoder': text_model_tree['params'],\n",
        "          # A new fusion layer. The user can initialize it later.\n",
        "          'fusion_layer': {\n",
        "              'kernel': np.empty((512, 256)),\n",
        "              'bias': np.empty((256,)),\n",
        "          }\n",
        "      },\n",
        "      # Can also merge other things, like step counts etc.\n",
        "      'step': image_model_tree['step'],\n",
        "  }\n",
        "\n",
        "image_model_path = ...\n",
        "text_model_path = ...\n",
        "\n",
        "# The API would take multiple paths and apply the transform.\n",
        "final_model = ocp.load_and_transform(\n",
        "    merge_models_transform,\n",
        "    image_model_path,\n",
        "    text_model_path,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 18
    },
    {
      "metadata": {
        "id": "od9_eJ1M6CW4"
      },
      "cell_type": "markdown",
      "source": [
        "This example also highlights an important feature: any parameters in the target structure that are not explicitly populated from a source checkpoint (like 'fusion_layer') would be initialized from scratch. This makes it easy to combine pre-trained components with new, untrained ones.\n",
        "\n",
        "This planned API aims to provide maximum flexibility, making complex restoration and fine-tuning workflows more straightforward to implement."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

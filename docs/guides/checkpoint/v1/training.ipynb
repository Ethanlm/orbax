{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnKdma9TUAdz"
      },
      "source": [
        "# Checkpointing in a Training Loop TODO(b/409382939) add links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GuKM1CkUFxK"
      },
      "source": [
        "This guide covers the usage of the `training` module, designed around the basic concept of a training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0VCD5iqUUGq"
      },
      "outputs": [],
      "source": [
        "from orbax.checkpoint import v1 as ocp\n",
        "\n",
        "training = ocp.training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh3F2uBkUomK"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqu4tRuDbD2C"
      },
      "source": [
        "Let's dive in with a simple training loop example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q0O1EVeUpmf"
      },
      "source": [
        "We will use the `Checkpointer` API provided by the `training` module. The `Checkpointer` must be configured with a **root directory**, which represents a working directory where all checkpoints will be saved throughout the course of an experiment.\n",
        "\n",
        "The root directory is not itself a checkpoint; rather, it is a *container* of checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va4LBhNIVB4d"
      },
      "outputs": [],
      "source": [
        "root_directory = '/tmp/my-checkpoints'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5hHPcA-VRkv"
      },
      "source": [
        "We will assume the existence of a training state containing the keys `params` and `opt_state`, which are trees of `jax.Array`. The state also contains a key `step`, which is represented as an integer.\n",
        "\n",
        "Note that the arrays in the state will be sharded using a fully-replicated sharding, but the example would work equally well with any other sharding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45m6nQZFVRGx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import jax\n",
        "\n",
        "pytree = {\n",
        "    'params': {\n",
        "        'layer0': np.arange(16).reshape((8, 2)),\n",
        "    },\n",
        "    'opt_state': [np.arange(16)],\n",
        "}\n",
        "sharding = jax.sharding.NamedSharding(jax.sharding.Mesh(jax.devices(), ('x',)), jax.sharding.PartitionSpec())\n",
        "pytree = jax.tree.map(lambda x: jax.device_put(x, sharding), pytree)\n",
        "pytree['step'] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovpiOC0lbHNu"
      },
      "source": [
        "Let's set up our fake training loop. We will add a \"training step function\" that just increments the step. In reality, this would also compute gradients and update model parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZutvBEHGauAT"
      },
      "outputs": [],
      "source": [
        "def train_step(state):\n",
        "  state['step'] += 1\n",
        "  return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrRibK-AkPK0"
      },
      "source": [
        "Now, we can create a `Checkpointer` to begin saving a sequence of checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpxaJy6AkT7e"
      },
      "outputs": [],
      "source": [
        "with training.Checkpointer(root_directory) as ckptr:\n",
        "  num_steps = 10\n",
        "  for step in range(num_steps):\n",
        "    saved = ckptr.save_pytree(step, pytree)\n",
        "    assert saved\n",
        "    pytree = train_step(pytree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92rmWW0JlReG"
      },
      "source": [
        "Calling `load` with no arguments will automatically restore the latest saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqJwgcKTkoj8"
      },
      "outputs": [],
      "source": [
        "with training.Checkpointer(root_directory) as ckptr:\n",
        "  print(ckptr.load_pytree())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYHwlp85l4l6"
      },
      "source": [
        "## Checkpointer APIs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOsqZOX2l7Xx"
      },
      "source": [
        "Now, let's get into a bit more detail about how to interact with the `Checkpointer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zQEQcKYQ7pV"
      },
      "source": [
        "In general, we recommend using `Checkpointer` as a context manager, as shown in the examples below.\n",
        "\n",
        "```\n",
        "with Checkpointer(...) as ckptr:\n",
        "  ...\n",
        "```\n",
        "\n",
        "You can use it without the context manager, but make sure to call `close()` before the program exits to ensure the completion of any outstanding operations and to ensure resource cleanup.\n",
        "\n",
        "```\n",
        "ckptr = Checkpointer(...)\n",
        "...\n",
        "ckptr.close()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WevsXxglqX3j"
      },
      "source": [
        "### Saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkt7s14cMuDq"
      },
      "source": [
        "Calling `save` in the training loop automatically calls `should_save`, which determines whether or not a checkpoint should be saved at the given step, based on the configured saving frequency. If a save is performed `save` returns `True`; otherwise it returns `False`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGoHS31XNQf6"
      },
      "source": [
        "Whether or not a save should be performed can be controlled via `SaveDecisionPolicy`.\n",
        "\n",
        "By default, `ContinuousCheckpointingPolicy` is configured, which always saves *unless* a save is already ongoing.\n",
        "\n",
        "Other pre-configured policies include:\n",
        "- `FixedIntervalPolicy`: Saves every `n` steps.\n",
        "- `InitialSavePolicy`: Saves on the first step.\n",
        "- `PreemptionCheckpointingPolicy`: Saves on a step where a preemption signal is received by the JAX distributed system. This is useful for saving whenever a job is automatically restarted by the system.\n",
        "- `SpecificStepsPolicy`: Saves on the specific set of configured steps.\n",
        "\n",
        "The policies can be used in conjunction via `AnySavePolicy`, which performs a save if any of the sub-policies would perform a save at the given step.\n",
        "\n",
        "You may always implement your own policy. See `SaveDecisionPolicy` for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJ5dMBQsOYX1"
      },
      "outputs": [],
      "source": [
        "root_directory = '/tmp/my-checkpoints-1'\n",
        "with training.Checkpointer(root_directory, save_decision_policy=training.save_decision_policies.FixedIntervalPolicy(3)) as ckptr:\n",
        "  for step in range(10):\n",
        "    ckptr.save_pytree(step, pytree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXUXTDW1OcLy"
      },
      "outputs": [],
      "source": [
        "!ls {root_directory}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UShFIikFqY4F"
      },
      "source": [
        "Now let's exercise some additional save features. These include:\n",
        "\n",
        "- `custom_metadata`: A JSON-formatted object intended for storing any user-specified properties. Custom metadata can be specified at both the root directory level and the individual checkpoint level. At the root level, the metadata should pertain to all checkpoints. For example, the experiment name is shared by all checkpoints within the root directory, while a property like `is_final` has different values for different checkpoints.\n",
        "-  `force`: Performs a save at the current step regardless of what would ordinarily be dictated by the `SaveDecisionPolicy`.\n",
        "- `metrics`: A JSON-formatted object storing evaluation metrics for the current step. This can be useful for ordering and garbage collecting checkpoints; more on that below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTEbnBPuqZAK"
      },
      "outputs": [],
      "source": [
        "root_directory = '/tmp/my-checkpoints-2'\n",
        "with training.Checkpointer(root_directory, save_decision_policy=training.save_decision_policies.FixedIntervalPolicy(3), custom_metadata={'experiment_name': 'my-experiment'}) as ckptr:\n",
        "  num_steps = 10\n",
        "  for step in range(num_steps):\n",
        "    is_final = step == num_steps - 1\n",
        "    ckptr.save_pytree(\n",
        "        step,\n",
        "        pytree,\n",
        "        metrics={'accuracy': 0.85},\n",
        "        custom_metadata={'is_final': is_final},\n",
        "        force=is_final,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdOIiUQAPtWq"
      },
      "outputs": [],
      "source": [
        "!ls {root_directory}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJj2HSYcP5N7"
      },
      "source": [
        "We will learn more about how to access some of the attributes that we saved in the sections below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1AQnHNtmcSd"
      },
      "source": [
        "### Querying Available Checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMUNCsR9lWw7"
      },
      "source": [
        "We can learn about which checkpoints are available by using `latest` and `checkpoints`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PSo8Xd8RaQk"
      },
      "outputs": [],
      "source": [
        "ckptr = training.Checkpointer(root_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke6KnvUJmv9G"
      },
      "source": [
        "Each of these APIs returns `CheckpointMetadata` objects, which store a number of properties describing each checkpoint. Some metadata properties are more expensive to retrieve than others though. The `latest` and `checkpoints` APIs just store a limited set of cheaply-retrievable properties, like the `step`. These APIs also make use of caching as much as possible, to avoid repeated disk reads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GI_UuRFPlld1"
      },
      "outputs": [],
      "source": [
        "# Returns CheckpointMetadata or None, if no checkpoints are found.\n",
        "latest = ckptr.latest\n",
        "assert latest is not None\n",
        "print(latest.step)\n",
        "print(latest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB19MrE2noKP"
      },
      "source": [
        "### Inspecting Checkpoint Metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv3kbWJ2nrfw"
      },
      "source": [
        "In many cases, we wish to cheaply gain information about checkpoint properties without loading the entire model. Using the `pytree_metadata` API, we can learn about the tree structure of our PyTree, as well as information about each array in the tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VuXqbq_R6mP"
      },
      "source": [
        "Like loading methods, metadata methods accept either no argument, or an argument representing the step to retrieve metadata for.\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD6gImyuSI8e"
      },
      "outputs": [],
      "source": [
        "# Loads metadata from the latest checkpoint.\n",
        "ckptr.pytree_metadata()\n",
        "# Loads metadata corresponding to the first step.\n",
        "ckptr.pytree_metadata(ckptr.checkpoints[0])\n",
        "# Loads metadata from a specific integer step.\n",
        "ckptr.pytree_metadata(3)\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs5di69uSlqx"
      },
      "source": [
        "Let's examine the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOdcOkomnq4g"
      },
      "outputs": [],
      "source": [
        "ckptr.pytree_metadata()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzZmGRhQQ1W_"
      },
      "source": [
        "Let's dig into a few specific fields. In particular, we can access `custom_metadata` and `metrics` that were saved previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HYHZ_qVRvIC"
      },
      "outputs": [],
      "source": [
        "print(ckptr.pytree_metadata().metrics)\n",
        "print(ckptr.pytree_metadata().custom_metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Ec6BCjSpVj"
      },
      "source": [
        "Within the metadata object, there is another field called `metadata`. This stores information specific to the structure of the object we saved. In this case, it describes the structure of the PyTree and array properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcVGNyVGSoow"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "pprint.pprint(ckptr.pytree_metadata().metadata)"
      ]
    },
    {
      "metadata": {
        "id": "m37bZn4Fh0iT"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, we can also retrieve the root-level metadata. Recall that this metadata is intended to describe the entire sequence of checkpoints, rather than just a single checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6h7gXHuTPz0"
      },
      "outputs": [],
      "source": [
        "ckptr.root_metadata()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IePA8i_aTGW0"
      },
      "source": [
        "### Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjPUDl_BTVxC"
      },
      "source": [
        "As we saw above with the `metadata` methods, we can load in a variety of ways."
      ]
    },
    {
      "metadata": {
        "id": "jBy6DMtOh5jQ"
      },
      "cell_type": "code",
      "source": [
        "# Loads from the latest checkpoint.\n",
        "ckptr.load_pytree()\n",
        "# Loads the first available checkpoint in the root directory.\n",
        "ckptr.load_pytree(ckptr.checkpoints[0])\n",
        "# Loads from a specific integer step.\n",
        "ckptr.load_pytree(3)\n",
        "\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08PeuedkWUzH"
      },
      "source": [
        "When dealing with PyTrees, particularly PyTrees with sharded `jax.Array` leaves, it is important for any non-toy use cases to specify an \"abstract PyTree\" that is used to guide restoration. Checkpoints are complicated objects. The abstract PyTree acts as an assertion to verify that the checkpoint has structure you expect and that arrays have the correct shapes.\n",
        "\n",
        "The abstract PyTree can also be used to instruct Orbax how to load the PyTree. The `dtype` property may be used to cast arrays, while the `sharding` property is used to correctly place array shards on devices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdlJdA2-uUPB"
      },
      "source": [
        "We should define an abstract tree with the same structure as the tree we originally saved. For the leaves, we specify different shardings than we originally saved with, and different dtypes as well, causing the loaded arrays to be cast and resharded when loading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o32JgrxMuYY1"
      },
      "outputs": [],
      "source": [
        "sharding = jax.sharding.NamedSharding(jax.sharding.Mesh(jax.devices(), ('x',)), jax.sharding.PartitionSpec('x'))\n",
        "abstract_pytree = {\n",
        "    'params': {\n",
        "        'layer0': jax.ShapeDtypeStruct((8, 2), np.float32, sharding=sharding),\n",
        "    },\n",
        "    'opt_state': [jax.ShapeDtypeStruct((16,), np.float32, sharding=sharding)],\n",
        "    'step': 0,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDoiDVTTYxbU"
      },
      "outputs": [],
      "source": [
        "ckptr.load_pytree(None, abstract_pytree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNs8H7rxwAUv"
      },
      "source": [
        "More details on working with PyTrees in such a manner can be found at TODO(link)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wfYSzqqwGzc"
      },
      "source": [
        "### Checkpointables TODO(link)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Af1jbAIdMb"
      },
      "source": [
        "`Checkpointer` supports the concept of `checkpointables`. See the documentation on \"Working with Checkpointables\" for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEiyZhMlYcX4"
      },
      "source": [
        "In simplified terms, a \"checkpointable\" refers to a distinct piece of the overall checkpoint, which can be thought of as a bundle. The `PyTree` training state is one such checkpointable. The dataset iterator is another. Checkpointing the position of the dataset iterator can be useful to ensure training resumes where we were interrupted not just for the model parameters, but for the data as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQctHlwvYpbT"
      },
      "source": [
        "We can see this concept in concrete terms using a Grain dataset iterator. See [Grain documentation](https://google-grain.readthedocs.io/en/latest/index.html) for more information. For our purposes, we can construct a toy dataset iterator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eB21TDs3ZjT8"
      },
      "outputs": [],
      "source": [
        "import grain\n",
        "\n",
        "dataset = iter(\n",
        "    grain.MapDataset.range(30)\n",
        "    .batch(3)\n",
        "    .map(lambda x: x.tolist())\n",
        ")\n",
        "\n",
        "pytree = {\n",
        "    'params': {\n",
        "        'layer0': np.arange(16).reshape((8, 2)),\n",
        "    },\n",
        "    'opt_state': [np.arange(16)],\n",
        "}\n",
        "sharding = jax.sharding.NamedSharding(jax.sharding.Mesh(jax.devices(), ('x',)), jax.sharding.PartitionSpec())\n",
        "pytree = jax.tree.map(lambda x: jax.device_put(x, sharding), pytree)\n",
        "pytree['step'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z2o_aXX_W-I"
      },
      "outputs": [],
      "source": [
        "def train_step(state, ds):\n",
        "  next(ds)  # Advances the dataset iterator\n",
        "  state['step'] += 1\n",
        "  return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emElV88eCVmy"
      },
      "source": [
        "We can save ten checkpoints in sequence, including the dataset iterator, advancing the iterator once per step. At each step, the dataset iterator points to `[step*3, step*3+1, step*3+2]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2DQKYvw9tOC"
      },
      "outputs": [],
      "source": [
        "root_directory = '/tmp/my-checkpoints-3'\n",
        "num_steps = 10\n",
        "\n",
        "with training.Checkpointer(root_directory) as ckptr:\n",
        "  for step in range(num_steps):\n",
        "    ckptr.save_checkpointables(\n",
        "        step,\n",
        "        dict(pytree=pytree, dataset=dataset)\n",
        "    )\n",
        "    pytree = train_step(pytree, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47BHWL2gCrUs"
      },
      "source": [
        "After loading at step `5`, `new_dataset` points to position `5` of the iterator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlM6Aa2-_myr"
      },
      "outputs": [],
      "source": [
        "new_dataset = iter(\n",
        "    grain.MapDataset.range(30)\n",
        "    .batch(3)\n",
        "    .map(lambda x: x.tolist())\n",
        ")\n",
        "print(f'Initial position: {next(new_dataset)}')\n",
        "\n",
        "with training.Checkpointer(root_directory) as ckptr:\n",
        "  ckptr.load_checkpointables(\n",
        "      5,\n",
        "      dict(pytree=None, dataset=new_dataset)\n",
        "  )\n",
        "print(f'Loaded from checkpoint: {next(new_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DUcxheKDuIl"
      },
      "source": [
        "It's important to note that dataset loading is stateful. You need to instantiate an iterator object, pass it to `load_checkpointables`, and the checkpoint state will be restored into the iterator state of the dataset object."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//experimental/users/cpgaffney/colab:orbax_colab",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1FY9i7ItX7ioNzyDgM9DDxtNb1i9vfgQ-",
          "timestamp": 1746026820832
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

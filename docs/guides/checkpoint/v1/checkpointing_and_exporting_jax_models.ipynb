{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPkbwOinbyZa"
      },
      "source": [
        "### [TODO - Add Links for the checkpointing sections]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_objective_audience_v1_descriptive"
      },
      "source": [
        "# Checkpointing and Exporting JAX Models: An End-to-End Guide with Orbax\n",
        "\n",
        "This guide demonstrates a complete, end-to-end workflow for managing JAX models using the Orbax library, from robust training-time checkpointing to final model export. We will simulate a Flax/Optax setup to show how the `Checkpointer` API enables policy-based management and restoration of training states. Following that, we use the standalone `save_pytree` function to save the final parameters for inference. At the end, we export these parameters into a TensorFlow SavedModel with `orbax-export`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_title_v1_descriptive"
      },
      "source": [
        "## 1. Setup\n",
        "\n",
        "First, we set up the necessary environment by installing the required packages and importing the modules we'll use throughout this guide.\n",
        "\n",
        "Note: The following cells install the packages required for this guide. If you are running this within an internal Google environment where these dependencies are already available, these installation steps can be safely skipped."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_installation_markdown_v1"
      },
      "source": [
        "### Installation\n",
        "\n",
        "Install `orbax-checkpoint` for core checkpointing, `flax` and `optax` for the JAX model and optimizer, and `orbax-export` with `tensorflow` for exporting to the SavedModel format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "setup_installation_code_v1",
        "outputId": "1094004a-984c-4ad7-b357-76b0f671818f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (0.11.14)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.11/dist-packages (0.10.6)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (0.2.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (1.4.0)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (1.12.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (4.14.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (1.1.0)\n",
            "Requirement already satisfied: jax\u003e=0.5.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (0.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (2.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (6.0.2)\n",
            "Requirement already satisfied: tensorstore\u003e=0.1.71 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (0.1.74)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (5.29.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (4.12.3)\n",
            "Requirement already satisfied: simplejson\u003e=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint) (3.20.1)\n",
            "Requirement already satisfied: rich\u003e=11.1 in /usr/local/lib/python3.11/dist-packages (from flax) (13.9.4)\n",
            "Requirement already satisfied: treescope\u003e=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax) (0.1.9)\n",
            "Requirement already satisfied: chex\u003e=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax) (0.1.89)\n",
            "Requirement already satisfied: jaxlib\u003e=0.4.27 in /usr/local/lib/python3.11/dist-packages (from optax) (0.5.1)\n",
            "Requirement already satisfied: toolz\u003e=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex\u003e=0.1.87-\u003eoptax) (0.12.1)\n",
            "Requirement already satisfied: ml_dtypes\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax\u003e=0.5.0-\u003eorbax-checkpoint) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax\u003e=0.5.0-\u003eorbax-checkpoint) (3.4.0)\n",
            "Requirement already satisfied: scipy\u003e=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax\u003e=0.5.0-\u003eorbax-checkpoint) (1.15.3)\n",
            "Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich\u003e=11.1-\u003eflax) (3.0.0)\n",
            "Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich\u003e=11.1-\u003eflax) (2.19.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]-\u003eorbax-checkpoint) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]-\u003eorbax-checkpoint) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]-\u003eorbax-checkpoint) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich\u003e=11.1-\u003eflax) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install orbax-checkpoint flax optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLJZrd-QCbfg",
        "outputId": "21204f21-c167-49db-8bd9-3a40bc1c3905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: orbax-export in /usr/local/lib/python3.11/dist-packages (0.0.6)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from orbax-export) (1.4.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from orbax-export) (0.6.7)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.11/dist-packages (from orbax-export) (1.12.2)\n",
            "Requirement already satisfied: jax\u003e=0.4.34 in /usr/local/lib/python3.11/dist-packages (from orbax-export) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from orbax-export) (0.5.1)\n",
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.11/dist-packages (from orbax-export) (0.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from orbax-export) (2.0.2)\n",
            "Requirement already satisfied: orbax-checkpoint\u003e=0.9.0 in /usr/local/lib/python3.11/dist-packages (from orbax-export) (0.11.14)\n",
            "Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers\u003e=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,\u003e=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard\u003c2.19,\u003e=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras\u003e=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py\u003e=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes\u003c0.5.0,\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow) (0.45.1)\n",
            "Requirement already satisfied: scipy\u003e=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax\u003e=0.4.34-\u003eorbax-export) (1.15.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (0.16.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint\u003e=0.9.0-\u003eorbax-export) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint\u003e=0.9.0-\u003eorbax-export) (6.0.2)\n",
            "Requirement already satisfied: tensorstore\u003e=0.1.71 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint\u003e=0.9.0-\u003eorbax-export) (0.1.74)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint\u003e=0.9.0-\u003eorbax-export) (1.6.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint\u003e=0.9.0-\u003eorbax-export) (4.12.3)\n",
            "Requirement already satisfied: simplejson\u003e=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint\u003e=0.9.0-\u003eorbax-export) (3.20.1)\n",
            "Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.19,\u003e=2.18-\u003etensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.19,\u003e=2.18-\u003etensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard\u003c2.19,\u003e=2.18-\u003etensorflow) (3.1.3)\n",
            "Requirement already satisfied: marshmallow\u003c4.0.0,\u003e=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json-\u003eorbax-export) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect\u003c1,\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json-\u003eorbax-export) (0.9.0)\n",
            "Requirement already satisfied: wadler-lindig\u003e=0.1.3 in /usr/local/lib/python3.11/dist-packages (from jaxtyping-\u003eorbax-export) (0.1.6)\n",
            "Requirement already satisfied: mypy-extensions\u003e=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect\u003c1,\u003e=0.4.0-\u003edataclasses-json-\u003eorbax-export) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard\u003c2.19,\u003e=2.18-\u003etensorflow) (3.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]-\u003eorbax-checkpoint\u003e=0.9.0-\u003eorbax-export) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]-\u003eorbax-checkpoint\u003e=0.9.0-\u003eorbax-export) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]-\u003eorbax-checkpoint\u003e=0.9.0-\u003eorbax-export) (3.23.0)\n",
            "Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install orbax-export tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_imports_markdown_v1_descriptive"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_imports_code_v1_descriptive"
      },
      "outputs": [],
      "source": [
        "from orbax.checkpoint import v1 as ocp\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import flax.linen as nn\n",
        "import optax\n",
        "import os\n",
        "import shutil\n",
        "from etils import epath\n",
        "from jax import tree_util"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_helper_markdown_v1_descriptive"
      },
      "source": [
        "### Helper for Directory Management\n",
        "\n",
        "A utility function to ensure a clean state for our checkpointing directories during each run of this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "setup_helper_code_v1_descriptive",
        "outputId": "77a3ef71-b107-4d2e-b941-28d93a737c61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tutorial artifacts will be saved under: /tmp/orbax_tutorial\n"
          ]
        }
      ],
      "source": [
        "def cleanup_directory_if_exists(path_str):\n",
        "    \"\"\"Removes a directory if it exists.\"\"\"\n",
        "    path = epath.Path(path_str)\n",
        "    if path.exists():\n",
        "        shutil.rmtree(path)\n",
        "\n",
        "tutorial_base_dir = epath.Path('/tmp/orbax_tutorial')\n",
        "cleanup_directory_if_exists(str(tutorial_base_dir))\n",
        "tutorial_base_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Tutorial artifacts will be saved under: {tutorial_base_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "define_state_title_v1_descriptive"
      },
      "source": [
        "## 2. Define a Simulated JAX State\n",
        "\n",
        "We'll construct a PyTree representing our model's training state. This typically includes model parameters, optimizer state, and the current training step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "define_state_model_markdown_v1_descriptive"
      },
      "source": [
        "### Define a Model and Training State\n",
        "\n",
        "We will define a basic Flax model, initialize its parameters, and create an Optax optimizer. The complete training state (model parameters, optimizer state, and step count) is stored in a Python dictionary. Sharding is applied to array elements using `jax.device_put`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "define_state_model_code_v1_orbax_intro_aligned",
        "outputId": "a92d7e1d-9130-4e27-dd68-a09bd43ad0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized JAX training state PyTree with explicit sharding.\n"
          ]
        }
      ],
      "source": [
        "# Model Hyperparameters\n",
        "input_dim = 64\n",
        "hidden_dim = 32\n",
        "output_dim = 10\n",
        "batch_size_for_init = 4\n",
        "\n",
        "class SimpleFlaxModel(nn.Module):\n",
        "    hidden_dim: int\n",
        "    output_dim: int\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        x = nn.Dense(features=self.hidden_dim, name=\"d1\")(x)\n",
        "        x = nn.relu(x)\n",
        "        return nn.Dense(features=self.output_dim, name=\"d2\")(x)\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "model_instance = SimpleFlaxModel(hidden_dim, output_dim)\n",
        "\n",
        "# Initialize model parameters with dummy data.\n",
        "dummy_input_for_flax_init = jnp.ones((batch_size_for_init, input_dim))\n",
        "initial_model_params_template = model_instance.init(key, dummy_input_for_flax_init)['params']\n",
        "np_params = jax.tree_util.tree_map(np.array, initial_model_params_template)\n",
        "\n",
        "# Initialize the optimizer state.\n",
        "optimizer_instance = optax.adam(1e-3)\n",
        "np_opt_state_template = optimizer_instance.init(initial_model_params_template)\n",
        "# Convert all array-like elements to NumPy arrays, leaving others (like `count`) as-is.\n",
        "np_opt_state = jax.tree_util.tree_map(lambda x: np.array(x) if hasattr(x, 'shape') else x, np_opt_state_template)\n",
        "\n",
        "# Define sharding for the model (replicated across all devices).\n",
        "mesh = jax.sharding.Mesh(jax.devices(), ('data',))\n",
        "replicated_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec())\n",
        "\n",
        "# Group components and apply sharding to all NumPy arrays in the PyTree.\n",
        "pytree_components_np = {\n",
        "    'params': np_params,\n",
        "    'opt_state': np_opt_state,\n",
        "}\n",
        "pytree_components_jax = jax.tree_util.tree_map(lambda x: jax.device_put(x, replicated_sharding) if isinstance(x, np.ndarray) else x, pytree_components_np)\n",
        "\n",
        "# Combine everything into the final training state PyTree.\n",
        "simulated_train_state = {**pytree_components_jax, 'step': 0}\n",
        "print(\"Initialized JAX training state PyTree with explicit sharding.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orbax_workflow_title_v1_orbax_intro_aligned"
      },
      "source": [
        "## 3. Orbax Checkpointing Workflow\n",
        "\n",
        "This section covers managing checkpoints during a simulated training loop using `Checkpointer`. This API is designed for common training scenarios and allows for powerful configuration through save policies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orbax_workflow_policies_setup_markdown_v1_orbax_intro_aligned"
      },
      "source": [
        "### Create a Checkpointing Directory\n",
        "\n",
        "We'll create a dedicated directory to store our training checkpoints and define a constant for our save interval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orbax_workflow_policies_setup_code_v1_orbax_intro_aligned"
      },
      "outputs": [],
      "source": [
        "training_ckpt_dir = tutorial_base_dir / 'simulated_training_ckpts'\n",
        "cleanup_directory_if_exists(str(training_ckpt_dir))\n",
        "training_ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "SAVE_INTERVAL_STEPS = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orbax_workflow_sim_train_markdown_v1_orbax_intro_aligned"
      },
      "source": [
        "### Checkpointing During a Simulated Training Loop\n",
        "\n",
        "We use `Checkpointer` as a context manager and configure it with a `FixedIntervalPolicy`. Inside the loop, `save_pytree(...)` is called on every step, but the policy ensures that a checkpoint is only written to disk when the condition (e.g., `step % 2 == 0`) is met."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orbax_workflow_sim_train_code_v1_orbax_intro_aligned_final",
        "outputId": "e50aaa9e-78f0-4dbe-8c5f-02392a9bc017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulating 7 training steps...\n",
            "  Saved checkpoint for step 0...\n",
            "  Saved checkpoint for step 2...\n",
            "  Saved checkpoint for step 4...\n",
            "  Saved checkpoint for step 6...\n"
          ]
        }
      ],
      "source": [
        "# A simplified function to simulate a single training step.\n",
        "def train_step_for_loop(state):\n",
        "  new_state = state.copy() # Work with a mutable copy of the state dict.\n",
        "  new_state['step'] += 1\n",
        "  # For this demo, we simulate param changes by adding small random noise.\n",
        "  key_for_noise = jax.random.PRNGKey(state['step'])\n",
        "  new_state['params'] = jax.tree_util.tree_map(\n",
        "        lambda p: p + 0.001 * jax.random.normal(key_for_noise, p.shape, p.dtype),\n",
        "        state['params']\n",
        "    )\n",
        "  return new_state\n",
        "\n",
        "current_loop_state = tree_util.tree_map(lambda x: x, simulated_train_state) # Start with a fresh copy.\n",
        "num_training_steps = 7\n",
        "\n",
        "print(f\"Simulating {num_training_steps} training steps...\")\n",
        "\n",
        "with ocp.training.Checkpointer(\n",
        "    directory=str(training_ckpt_dir),\n",
        "    save_decision_policy=ocp.training.save_decision_policies.FixedIntervalPolicy(SAVE_INTERVAL_STEPS)\n",
        ") as ckptr:\n",
        "    for _ in range(num_training_steps):\n",
        "        step_to_save_at = current_loop_state['step']\n",
        "\n",
        "        # `save_pytree` takes the current step, the state to save, and optional metrics.\n",
        "        saved = ckptr.save_pytree(step_to_save_at, current_loop_state, metrics={'accuracy': 0.85})\n",
        "\n",
        "        if saved: # Will be True if the save_decision_policy decided to save.\n",
        "            print(f\"  Saved checkpoint for step {step_to_save_at}...\")\n",
        "\n",
        "        current_loop_state = train_step_for_loop(current_loop_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orbax_workflow_resume_markdown_v1_orbax_intro_aligned"
      },
      "source": [
        "### Resuming from a Checkpoint\n",
        "\n",
        "To resume training, we use `training.Checkpointer.load_pytree`. Orbax-checkpoint can automatically find the latest completed checkpoint. We provide an `abstract_pytree` (an empty or example version of our state) to guide the restoration process and ensure the data is loaded with the correct structure and sharding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orbax_workflow_resume_code_v1_orbax_intro_aligned",
        "outputId": "02ad7a63-7406-4939-c145-233a1de3fc7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restoring from latest checkpoint: step 6...\n",
            "Restored state. Internal step of loaded state: 6\n"
          ]
        }
      ],
      "source": [
        "with ocp.training.Checkpointer(directory=str(training_ckpt_dir)) as ckptr:\n",
        "    print(f\"Restore from the latest checkpoint in {training_ckpt_dir}...\")\n",
        "\n",
        "    # It returns None if no checkpoint is found.\n",
        "    resumed_train_state = ckptr.load_pytree(\n",
        "        abstract_pytree=simulated_train_state # Provide an abstract state for structure and sharding.\n",
        "    )\n",
        "\n",
        "# If a checkpoint was successfully loaded, resumed_train_state will not be None.\n",
        "if resumed_train_state is not None:\n",
        "    print(f\"Restored state successfully. Resuming from step: {resumed_train_state['step']}\")\n",
        "    with ocp.training.Checkpointer(directory=str(training_ckpt_dir)) as ckptr:\n",
        "        assert resumed_train_state['step'] == ckptr.latest.step\n",
        "else:\n",
        "    # If no checkpoint was found, fall back to the initial state.\n",
        "    print(\"No checkpoint found to restore; using initial state.\")\n",
        "    resumed_train_state = simulated_train_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "export_params_title_v1_free_fn_descriptive"
      },
      "source": [
        "## 4. Saving Final JAX Parameters for Export\n",
        "\n",
        "After training, you often need to save just the final model parameters for inference or export. For this, Orbax provides the simple `save_pytree` function, which is ideal for one-off saves without the overhead of training policies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "export_params_dir_extract_markdown_v1_free_fn"
      },
      "source": [
        "### Extract Final Parameters for Saving\n",
        "\n",
        "We extract the learned parameters from our final training state, as this is the only part we need for inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "export_params_dir_extract_code_v1_orbax_intro_style",
        "outputId": "a8db3e37-b4a6-4f03-b6ba-d9cbde1d1272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final model parameters extracted for saving.\n"
          ]
        }
      ],
      "source": [
        "final_params_save_dir = tutorial_base_dir / 'exported_model_params_orbax'\n",
        "final_model_params_to_save = current_loop_state['params']\n",
        "print(\"Final model parameters extracted for saving.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "export_params_save_pytree_markdown_v1_descriptive"
      },
      "source": [
        "### Using `save_pytree` for the Final Save\n",
        "\n",
        "`save_pytree` directly saves the given PyTree to the specified directory. It's a straightforward way to persist the final artifacts of a training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "export_params_save_pytree_code_v1_descriptive",
        "outputId": "df655049-137a-4d05-c180-420bee1575e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving final parameters to: /tmp/orbax_tutorial/exported_model_params_orbax...\n",
            "Final model parameters saved via `save_pytree`.\n"
          ]
        }
      ],
      "source": [
        "# Ensure a clean state by removing the directory if it exists from a previous run.\n",
        "cleanup_directory_if_exists(str(final_params_save_dir))\n",
        "\n",
        "print(f\"Saving final parameters to: {final_params_save_dir}...\")\n",
        "ocp.save_pytree(\n",
        "    path=final_params_save_dir,\n",
        "    pytree=final_model_params_to_save,\n",
        "    overwrite=True #  overwrites an existing checkpoint in directory\n",
        ")\n",
        "print(\"Final model parameters saved via `save_pytree`.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "export_params_load_pytree_markdown_v1_descriptive"
      },
      "source": [
        "### Loading Exported Parameters (Verification)\n",
        "\n",
        "We can use `load_pytree` to load the parameters back and verify that the save operation was successful. Again, we can pass an `abstract_pytree` to help guide the restoration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "export_params_load_code_v1_orbax_intro_style",
        "outputId": "04df13f5-eafd-4042-e5b4-8ba094a78ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading parameters from /tmp/orbax_tutorial/exported_model_params_orbax for verification...\n",
            "Verification: PASSED\n"
          ]
        }
      ],
      "source": [
        "if final_params_save_dir.exists() and len(os.listdir(str(final_params_save_dir))) \u003e 0:\n",
        "    print(f\"Loading parameters from {final_params_save_dir} for verification...\")\n",
        "    loaded_final_params = ocp.load_pytree(\n",
        "        final_params_save_dir,\n",
        "        abstract_pytree=final_model_params_to_save # Use instance as a template for structure and sharding.\n",
        "    )\n",
        "    # Check that the loaded parameters match the original ones.\n",
        "    params_match = jax.tree_util.tree_all(\n",
        "        jax.tree_util.tree_map(jnp.array_equal, final_model_params_to_save, loaded_final_params)\n",
        "    )\n",
        "    print(f\"Verification: {'PASSED' if params_match else 'FAILED'}\")\n",
        "else:\n",
        "    print(\"Saved parameters directory not found or empty. Skipping verification.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYTJ8lA0Vow_"
      },
      "source": [
        "## 5. Exporting to TensorFlow SavedModel\n",
        "\n",
        "This section demonstrates converting the saved JAX model parameters into a TensorFlow SavedModel format using the [`orbax-export`](https://orbax.readthedocs.io/en/latest/guides/export/orbax_export_101.html) library. This is a common step for for exporting JAX models to TensorFlow [SavedModel](https://www.tensorflow.org/guide/saved_model) format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWaTQBeQV4kE"
      },
      "outputs": [],
      "source": [
        "from orbax.export import ExportManager, JaxModule, ServingConfig\n",
        "from orbax.export.validate.validation_manager import ValidationManager\n",
        "import tensorflow as tf\n",
        "import traceback\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCsiNFW5V7cI"
      },
      "source": [
        "### Define JAX Model Apply Function and Pre/Post-processing for Export\n",
        "\n",
        "For [`orbax-export`](https://orbax.readthedocs.io/en/latest/guides/export/orbax_export_101.html), we need to provide a JAX function that takes `(params, inputs)`. We can also define TensorFlow-based pre-processing and post-processing functions, which will be included in the SavedModel's computation graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTCWv3GmV77-",
        "outputId": "b66f11d1-01d9-454a-cfe9-b333a61bec9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JAX apply function and plain TF pre/post-processing functions defined for export.\n"
          ]
        }
      ],
      "source": [
        "# `model_instance` was defined in Section 2 (the SimpleFlaxModel instance).\n",
        "# `final_model_params_to_save` contains the parameters we want to export from Section 4.\n",
        "\n",
        "# JAX Apply Function: The core JAX logic for the model's forward pass.\n",
        "@jax.jit\n",
        "def jax_model_apply_fn_for_export(params, inputs):\n",
        "  \"\"\"A JAX function with the signature (params, inputs) for orbax-export.\"\"\"\n",
        "  return model_instance.apply({'params': params}, inputs)\n",
        "\n",
        "\n",
        "# Optional: TF Pre-processing Function.\n",
        "def tf_preprocess_fn_for_export(input_tensor: tf.Tensor) -\u003e tf.Tensor:\n",
        "  \"\"\"Normalizes the raw input tensor. Orbax-export will trace this into a graph.\"\"\"\n",
        "  return tf.cast(input_tensor, tf.float32) / 255.0\n",
        "\n",
        "\n",
        "# Optional: TF Post-processing Function.\n",
        "def tf_postprocess_fn_for_export(output_tensor: tf.Tensor) -\u003e dict[str, tf.Tensor]:\n",
        "  \"\"\"Packages the model output into a dictionary. Orbax-export will trace this.\"\"\"\n",
        "  return {'predictions': output_tensor}\n",
        "\n",
        "print(\"JAX apply function and plain TF pre/post-processing functions defined for export.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piBK2onEWBg9"
      },
      "source": [
        "### Create `JaxModule` and `ServingConfig`\n",
        "\n",
        "[`JaxModule`](https://orbax.readthedocs.io/en/latest/api_reference/export.jax_module.html#id1) wraps the JAX function and its parameters. [`ServingConfig`](https://orbax.readthedocs.io/en/latest/api_reference/export.serving_config.html#id1) defines the input signature for the SavedModel and specifies which pre/post-processing functions to use for a given serving signature key (e.g., `serving_default`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJmfCPyAWCDG",
        "outputId": "0f2834df-8835-4103-fb11-d92d9660152b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JaxModule and ServingConfig created successfully.\n"
          ]
        }
      ],
      "source": [
        "# Create the JaxModule, which encapsulates the JAX function and its parameters.\n",
        "jax_module_for_export = JaxModule(\n",
        "    params=final_model_params_to_save,\n",
        "    apply_fn=jax_model_apply_fn_for_export,\n",
        "    input_polymorphic_shape=f'(b, {input_dim})',\n",
        "    jax2tf_kwargs={'with_gradient': False, 'native_serialization': False}\n",
        ")\n",
        "\n",
        "# This tells orbax-export how to trace the Python preprocessor function.\n",
        "tf_input_signature = [\n",
        "    tf.TensorSpec(shape=[None, input_dim], dtype=tf.float32)\n",
        "]\n",
        "\n",
        "# Create a serving configuration that bundles the signature key, input specs,\n",
        "# and our Python processing functions.\n",
        "serving_config = ServingConfig(\n",
        "    signature_key='serving_default',\n",
        "    input_signature=tf_input_signature,\n",
        "    tf_preprocessor=tf_preprocess_fn_for_export,\n",
        "    tf_postprocessor=tf_postprocess_fn_for_export\n",
        ")\n",
        "print(\"JaxModule and ServingConfig created successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDFaIw5IWGhe"
      },
      "source": [
        "### Export to TensorFlow SavedModel\n",
        "\n",
        "The [`ExportManager`](https://orbax.readthedocs.io/en/latest/api_reference/export.export_manager.html#id1) takes the `JaxModule` and a list of `ServingConfig` to build and save the final TensorFlow SavedModel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPkb_TpsWHNp",
        "outputId": "1abe6d3e-b48c-444d-bab2-653c4b9460ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exporting SavedModel to: /tmp/orbax_tutorial/tf_saved_model_orbax_export\n",
            "Model exported successfully to SavedModel format.\n",
            "Contents of /tmp/orbax_tutorial/tf_saved_model_orbax_export: ['fingerprint.pb', 'assets', 'saved_model.pb', 'variables']\n"
          ]
        }
      ],
      "source": [
        "# Define the directory to save the final exported model.\n",
        "saved_model_dir = tutorial_base_dir / 'tf_saved_model_orbax_export'\n",
        "cleanup_directory_if_exists(str(saved_model_dir))\n",
        "saved_model_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# The ExportManager orchestrates the JAX-to-TF conversion and saving process.\n",
        "export_manager = ExportManager(jax_module_for_export, [serving_config])\n",
        "print(f\"Exporting SavedModel to: {saved_model_dir}\")\n",
        "try:\n",
        "    export_manager.save(str(saved_model_dir))\n",
        "    print(\"Model exported successfully to SavedModel format.\")\n",
        "    print(f\"Contents of {saved_model_dir}: {os.listdir(str(saved_model_dir))}\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR during SavedModel export: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L7ppIbb8OpE"
      },
      "source": [
        "### Validate the Exported Model\n",
        "\n",
        "A critical final step is to verify that the exported TensorFlow model produces the same results as the original JAX model. We use the [`ValidationManager`](https://orbax.readthedocs.io/en/latest/api_reference/export.validate.validation_manager.html#orbax.export.validate.validation_manager.ValidationManager), which compares the outputs of the JAX model and the loaded TF SavedModel for a given batch of inputs and generates a detailed report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0yelDULiIJW",
        "outputId": "3f8b4916-16fc-4089-a3a2-2dc8e2506d29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running validation...\n",
            "VERIFICATION PASSED! Status: Pass\n",
            "\n",
            "Validation Report:\n",
            "{\n",
            "  \"outputs\": {\n",
            "    \"FloatingPointDiffReport\": {\n",
            "      \"total\": 40,\n",
            "      \"max_diff\": 1.4901161193847656e-07,\n",
            "      \"max_rel_diff\": 5.774800229119137e-06,\n",
            "      \"all_close\": true,\n",
            "      \"all_close_absolute_tolerance\": 1e-07,\n",
            "      \"all_close_relative_tolerance\": 1e-07\n",
            "    },\n",
            "    \"NonFloatingPointDiffReport\": {\n",
            "      \"total_flattened_tensors\": 0,\n",
            "      \"mismatches\": 0,\n",
            "      \"mismatch_ratio\": 0.0,\n",
            "      \"max_non_floating_mismatch_ratio\": 0.01\n",
            "    }\n",
            "  },\n",
            "  \"latency\": {\n",
            "    \"baseline\": {\n",
            "      \"num_batches\": 1,\n",
            "      \"avg_in_ms\": 2.8274059295654297,\n",
            "      \"p90_in_ms\": 2.8274059295654297,\n",
            "      \"p99_in_ms\": 2.8274059295654297\n",
            "    },\n",
            "    \"candidate\": {\n",
            "      \"num_batches\": 1,\n",
            "      \"avg_in_ms\": 3.104686737060547,\n",
            "      \"p90_in_ms\": 3.104686737060547,\n",
            "      \"p99_in_ms\": 3.104686737060547\n",
            "    }\n",
            "  },\n",
            "  \"xprof_url\": {\n",
            "    \"baseline\": \"N/A\",\n",
            "    \"candidate\": \"N/A\"\n",
            "  },\n",
            "  \"metadata\": {\n",
            "    \"baseline\": {},\n",
            "    \"candidate\": {}\n",
            "  },\n",
            "  \"status\": 1\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Prepare a batch of test inputs. These should be \"raw\" (pre-preprocessing).\n",
        "validation_batch_size = 4\n",
        "raw_validation_inputs = np.random.rand(validation_batch_size, input_dim).astype(np.float32) * 255.0\n",
        "\n",
        "# To match the positional signature pass inputs as a list of lists.\n",
        "validation_mgr = ValidationManager(\n",
        "    module=jax_module_for_export,\n",
        "    serving_configs=[serving_config],\n",
        "    model_inputs=[[raw_validation_inputs]]\n",
        ")\n",
        "\n",
        "# Load the candidate model we want to validate.\n",
        "loaded_tf_model = tf.saved_model.load(str(saved_model_dir))\n",
        "\n",
        "# Run the validation, which compares the JAX and TF outputs.\n",
        "print(\"\\nRunning validation...\")\n",
        "validation_reports = validation_mgr.validate(loaded_tf_model)\n",
        "\n",
        "# Check the report. The report is a dict keyed by the signature_key.\n",
        "report = validation_reports['serving_default']\n",
        "\n",
        "# The report status is an enum. We check its string name for a simple pass/fail result.\n",
        "if report.status.name == 'Pass':\n",
        "    print(f\"VERIFICATION PASSED! Status: {report.status.name}\")\n",
        "else:\n",
        "    print(f\"VERIFICATION FAILED! Status: {report.status.name}\")\n",
        "\n",
        "# The report can be printed as a JSON string for detailed inspection of differences and latencies.\n",
        "print(\"\\nValidation Report:\")\n",
        "print(report.to_json(indent=2))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

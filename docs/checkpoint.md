# Checkpointing

https://github.com/google/orbax/blob/main/docs/checkpoint.md


## Introduction

Orbax provides a flexible and customizable for managing checkpoints for various
different objects.

Check out our
[colab](http://colab.research.google.com/github/google/orbax/blob/main/orbax//checkpoint/orbax_checkpoint.ipynb)
for some hands-on examples.


## CheckpointManager

[`CheckpointManager`](https://github.com/google/orbax/tree/main/orbax/checkpoint/checkpoint_manager.py)
is the highest-level object provided by Orbax for checkpointing, and is
generally the interface that should be most often used to interact with
checkpoints.

This manager allows saving and restoring any object for which a
`CheckpointHandler` implementation exists (see [below](#checkpointhandler)).
This may include objects such as
[JAX PyTree](https://jax.readthedocs.io/en/latest/pytrees.html),
[`tf.data.Iterator`](https://www.tensorflow.org/api_docs/python/tf/data/Iterator),
JSON-format dictionaries, and others.

A `CheckpointHandler` should be used in conjunction with a
[`Checkpointer`](#checkpointer) object. This allows customizing the logic used
to save the checkpoint atomically and synchronously (or asynchronously).

Here is a simple usage example:

```py
mngr = CheckpointManager('path/to/directory/', Checkpointer(PyTreeCheckpointHandler()))
item = {'a': 0, 'b': {'c': 1, 'd': 2}}
for step in range(10):
  mngr.save(step, item)
step = 10
restored = mngr.restore(step)
```

This allows saving and restoring a single PyTree object using a
`PyTreeCheckpointHandler`, wrapped with a `Checkpointer`, which performs the
save synchronously. A more complex case allows managing several different
objects and customizing `CheckpointManager` behavior.

```py
def best_fn(metrics: Mapping[str, float]) -> float:
  return metrics['accuracy']

options = CheckpointManagerOptions(max_to_keep=5, best_fn=best_fn, mode='max')
handlers = {'state': AsyncCheckpointer(PyTreeCheckpointHandler()), 'metadata': Checkpointer(JsonCheckpointHandler())}
mngr = CheckpointManager('path/to/directory/', handlers, options=options)

state = {'a': 0, 'b': {'c': 1, 'd': 2}}
metadata = {'learning_rate': 0.001, 'version': 1.1, 'exp_name': 'best_exp_123'}
for step in range(10):
  mngr.save(step, {'state': state, 'metadata': metadata},
              metrics={'accuracy': ...})
# do something else
mngr.wait_until_finished()  # wait for async save to complete.
restored = mngr.restore(step, items={'state': None, 'metadata': None})
restored_state, restored_metadata = restored['state'], restored['metadata']
```

In this example, we begin by specifying options for `CheckpointManager`, which
instruct it to keep a maximum of 5 checkpoints, and also to track metrics
associated with each checkpoint.

We can then give a dictionary of checkpointers with unique keys for every item
we want to save. Each key has a `Checkpointer` object as a value, which in turn
wraps a `CheckpointHandler` object. This instructs the `CheckpointManager` on
how to save the given object. When calling `save`, we provide a dictionary with
the same keys, each corresponding to an item to be saved.

Note that `AsyncCheckpointer` can be used in conjunction with supported
`CheckpointHandler` subclasses. This allows the save operation to proceed in a
background thread while waiting for completion.

After saving several checkpoints, the directory will look like this:

```
path/to/directory
  0/
    state/
      checkpoint  # binary flax.serialization file
      layer0/  # directory for each key in the PyTree
        <files generated by Tensorstore>
      layer1/
        ...
      .../
    metadata/
      <json file>
  1/
    ...
  2/
    ...
  .../
```

In this multi-object setting, we must also provide a dictionary of items to
restore. The value may be given as `None` if it is not needed by the underlying
`CheckpointHandler` to perform the restore operation. It then returns a
dictionary of restored objects with the same keys as provided.

Each `CheckpointHandler` may accept additional optional arguments. These can be
passed through from `CheckpointManager` to `Checkpointer` to `CheckpointHandler`
via `save_kwargs` and `restore_kwargs`. For example:

```py
empty_state = jax.tree_map(lambda _: object(), pytree_state)
save_args = jax.tree_map(lambda _: SaveArgs(...), pytree_state)
restore_args = jax.tree_map(lambda _: RestoreArgs(...), pytree_state)

mngr.save(step, items={'state': pytree_state, ...},
  save_kwargs={'state': {'save_args': save_args}})
mngr.restore(step, items={'state': empty_state, ...},
  save_kwargs={'state': {'restore_args': restore_args}})
```

Both `save_kwargs` and `restore_kwargs` are nested dictionaries where the
top-level keys correspond to the items to be checkpointed. The values are
dictionaries of optional arguments that are provided to `Checkpointer`, and then
to `CheckpointHandler`, as keyword arguments.

Other APIs include:

*   `all_steps`: returns an unsorted list of integers of steps saved in the
    `CheckpointManager`'s directory.
*   `latest_step`: returns the most recent step.
*   `best_step`: returns the best step as defined by the `best_fn` which runs
    over provided metrics. Returns the latest step if `best_fn` is not defined.
*   `should_save`: returns whether save should be performed or skipped at the
    given step. This depends on factors such as the most recent saved step as
    well as the specified save interval.
*   `wait_until_finished`: waits for any incomplete save operations to complete
    by calling the same method for any `AsyncCheckpointer`s. This will be a
    no-op if no `Checkpointer`s are async.
*   `structure`: returns a dictionary with the same items as the checkpointers
    originally passed to the manager. Delegates to the underlying `Checkpointer`
    and then to `CheckpointHandler`. For any `CheckpointHandler` which does not
    implement the method, that key will simply not be present in the returned
    dict.

## Checkpointer

[`Checkpointer`](https://github.com/google/orbax/tree/main/orbax/checkpoint/checkpointer.py)
serves as an intermediate layer between the high-level APIs of
`CheckpointManager` and the lower-level, per-type logic of `CheckpointHandler`.
It's purpose is to provide a no-frills way to atomically save an individual
object, while also retaining its independence as a separate layer in order to
better support customization. This is best illustrated by
[`AsyncCheckpointer`](#asynccheckpointer), which provides generalized logic for
saving objects in a background thread.

This class may be a good option if you only want to save or restore a single
object from a specific directory, and do not care about extra functionality that
tracks steps or best metrics, for example.

`Checkpointer` only provides `save`, `restore`, and `structure` APIs. Each of
these ultimately delegates to underlying `CheckpointHandler` provided at
construction. For `save`, however, the `Checkpointer` ensures that the operation
will be atomic.

### AsyncCheckpointer

[`AsyncCheckpointer`](https://github.com/google/orbax/tree/main/orbax/checkpoint/async_checkpointer.py)
is similar in almost every way to `Checkpointer`, but the save operation happens
in a background thread, while returning immediately to allow the main thread to
do something else. However, the operation is guaranteed to be eventually atomic.

Unlike `Checkpointer`, which can wrap any `CheckpointHandler`,
`AsyncCheckpointer` can only wrap `AsyncCheckpointHandler`, because it requires
the async save method that this subclass provides.

Users should call `wait_until_finished` to block until completion of outstanding
save operations.

## CheckpointHandler

IMPORTANT: `CheckpointHandler` is not intended to be used alone, but only in
conjunction with `Checkpointer` or `CheckpointManager`.

[`CheckpointHandler`](https://github.com/google/orbax/tree/main/orbax/checkpoint/checkpoint_handler.py)
provides an interface which can be implemented to provide support for saving and
restoring a particular object. Several objects are supported by default in Orbax
(see [below](#checkpointhandler-implementations)).

The class provides `save` and `restore` APIs which save or restore an `item`
synchronously given a specific `directory`. The save operation should not be
atomic, since this functionality is handled by `Checkpointer`.

### AsyncCheckpointHandler

A special interface inheriting from `CheckpointHandler`,
[`AsyncCheckpointHandler`](https://github.com/google/orbax/tree/main/orbax/checkpoint/async_checkpoint_handler.py)
provides an additional async method called `async_save`, which has a similar
interface to `save`, but with significant differences.

Awaiting `async_save` should perform a copy of the object data from device to
host. The method should then return a list of futures which, when run, should
complete the saving of the object from host to storage location.

All subclasses of `AsyncCheckpointHandler` can easily implement their `save`
method by calling `async_save`.

## CheckpointHandler Implementations

### PyTreeCheckpointHandler

[`PyTreeCheckpointHandler`](https://github.com/google/orbax/tree/main/orbax/checkpoint/pytree_checkpoint_handler.py)
allows checkpointing PyTrees consisting of scalars, np/jnp arrays, or
`GlobalDeviceArray` (`GDA`). Note that this class provides support for
device-partitioned arrays via `GDA`. Other values are expected to be replicated
across devices.

This is a subclass of `AsyncCheckpointHandler`, which means that it allows
asynchronous saves via `async_save`.

For saving and restoring, `PyTreeCheckpointHandler` provides optional arguments
on a per-element basis via `SaveArgs` and `RestoreArgs`. This means that
parameters are provided on an individual basis for each element in the PyTree.

`SaveArgs` parameters include:

*   `use_flax`: if true, saves the given parameter using flax.serialization to a
    unified checkpoint file. Must be false if the given array value is a GDA.
*   `dtype`: if provided, casts the parameter to the given dtype before saving.
    Note that the parameter must be compatible with the given type (e.g.
    jnp.bfloat16 is not compatible with np.ndarray).

`RestoreArgs` parameters include:

*   `as_jax_array`: if true, restores the given parameter as a GlobalDeviceArray
    or jax.Array (depending on the setting of jax.config) regardless of how it
    was saved. If the array was not saved as a GDA, mesh and mesh_axes are
    required.
*   `mesh`: the device mesh that the array should be restored as. If None, uses
    a linear mesh of jax.devices.
*   `mesh_axes`: the mesh_axes that the array should be restored as. If None,
    fully replicates the array to every device.
*   `global_shapes`: the global shape that the array should be restored into. If
    not provided, the shape will be restored as written.
*   `lazy`: if True, restores using [LazyValue](#LazyValue). The actual read
    operation will not be performed until `get` is called for the restored
    LazyValue
*   `dtype`: if provided, casts the parameter to the given dtype after
    restoring. Note that the parameter must be compatible with the given type
    (e.g. jnp.bfloat16 is not compatible with np.ndarray).

`PyTreeCheckpointHandler` will create an individual directory for each nested
key. The exact naming of per-parameter directories can be customized by
overriding `_get_param_infos`. These parameters are saved using
[Tensorstore](https://google.github.io/tensorstore/). There is an additional
`checkpoint` file that will be created using
[`flax.serialization`](https://flax.readthedocs.io/en/latest/flax.serialization.html).
This stores the PyTree structure, as well as any parameters for which `use_flax`
was True at save time. Individual directories will not be created for these
parameters.

For `restore`, `item` is an optional argument because the PyTree structure can
be recovered from the saved checkpoint if `item` is a dictionary. However, if
`item` is an object other than `dict`, `item` should be provided in order to
restore the object structure.

### JsonCheckpointHandler

[`JsonCheckpointHandler`](https://github.com/google/orbax/tree/main/orbax/checkpoint/json_checkpoint_handler.py)
is provided as a way to checkpoint nested dictionaries that can be serialized in
JSON format. This can be useful as a way to store checkpoint metadata. For
example, `CheckpointManager` uses this class to store the metrics used to
evaluate relative checkpoint quality.

Note that presently, this class does not implement async APIs.

## Utilities

### LazyValue

[`LazyValue`](https://github.com/google/orbax/tree/main/orbax/checkpoint/lazy_array.py)
provides a mechanism for delayed loading of values from a checkpoint. If a
parameter is restored as a `LazyValue` (in `PyTreeCheckpointHandler`, setting
`RestoreArgs.lazy = True`), the restored object will not yet have done the work
of actually loading the parameter from Tensorstore.

The actual loading will only be done when `.get()` is called on the `LazyValue`.

Of course, for parameters saved using `flax.serialization` into a file
containing many parameters, the loading does happen eagerly, regardless of
whether `LazyValue` is used. However, parameters saved in this way should
typically be small.

### Transformations

The
[`transform_utils`](https://github.com/google/orbax/tree/main/orbax/checkpoint/transform_utils.py)
library provides functions to allow structural PyTree transformations, which can
facilitate migrations between different checkpoint versions.

The API consists of a `Transform` class and an `apply_transformations` function.

#### Transform

`Transform` consists of the following elements:

*   `original_key`: Denotes the original name of the key. Represented as a
    string with '/' denoting successive levels of nesting. If the key
    corresponding to this Transform is a regex, backreferences (such as \1) will
    be replaced with the appropriate matched group in the regex. Note: not
    needed if multi_value_fn is provided.
*   `use_fallback`: if True, takes the value from the fallback tree. If
    `default_to_original=True` in `apply_transformations`, the fallback tree is
    `new_tree`. If `default_to_original=False` in `apply_transformations`, the
    fallback tree is `original_tree`.
*   `value_fn`: A function accepting a single value and returning a single
    value. The value provided as an argument is the value of the transformation
    key in the original PyTree.
*   `multi_value_fn`: A function accepting a PyTree and returning any value. The
    PyTree argument will be the original PyTree, and the function should return
    the value of the key in the new PyTree.

This can be represented with some simple examples:

`{'a': Transform(original_key='b')}`

This denotes that the original key was named 'b', but we are changing it to 'a'.

`{'a': Transform(value_fn=lambda kv: kv['b'] * 2)}`

This signifies that the new key 'a' is the old key 'b' multiplied by two.

`{r'(.*)a(.*)': Transform(original_key=r'\1b\2'}`

This denotes that keys containing 'b' should be substituted to 'a'. This may
apply to multiple different keys at different levels of nesting. The '/'
character denotes a successive level of nesting.

#### Using Transformations

The `apply_transformations` function accepts an original PyTree, a PyTree of
`Transform` objects and a "new" Pytree. The function will return a PyTree
matching `new_tree`.

For example:

```py
original_tree = {
  'a': 1,
  'b': {
    'c': 5,
    'd': [0, 1, 2, 3]
  },
  'f': 2,
  'b1': {
    'c': 2,
  },
  'b2': {
    'c': 3,
  },
}
transformations = {
  'a1': Transform(original_key='a'),  # rename
  # another way of doing above
  'a1': Transform(multi_value_fn=lambda kv: kv['a']),
  'b': {
    # doubled original
    'c': Transform(multi_value_fn=lambda kv: kv['b']['c'] * 2)
    # drop b/d
  },
  # Copy original into multiple new keys
  'c1': Transform(original_key='b/c'),
  'c2': Transform(original_key='b/c'),
  # one to many mapping
  'x': Transform(multi_value_fn=lambda kv: kv['b']['d'][0]),
  'y': Transform(multi_value_fn=lambda kv: kv['b']['d'][1:]),
  # many to one mapping
  'z': Transform(multi_value_fn=lambda kv: kv['a'] * 2 + sum(kv['b']['d'])),
  r'x(\d.*)': Transform(original_key=r'b\1')
}

# defines the structure of the result
new_tree = {
  'a1': ...,
  'a1': ...,
  'b': {
    'c': ...,
  },
  'c1': ...,
  'c2': ...,
  'x': ...,
  'y': ...,
  'z': ...,
  # 'f' defined in original_tree and new_tree, but not in transforms. Value
  # carried over from original_tree.
  'f': ...,
  # This value matters since it is not present in original_tree or
  # transformations, so the value here will simply be preserved in the result.
  'g': 5,
  # These are just 'b1', 'b2', but renamed to 'x1', 'x2', with all values
  # copied over.
  'x1': {
    'c': 2,
  }
  'x2': {
    'c': 3,
  }
}

transformed_tree = apply_transformations(original_tree, transforms, new_tree)
```

Note that there is an additional option for `apply_transformations`, which is
`default_to_original` (True by default). This means that the values keys
unspecified in `transformations` but present in *both* trees will be taken from
the *original* tree. If False, such values will be taken from the *new* tree.

Remember that if a key is present in the new tree, but not in the old, the value
will simply be taken from the new tree. If a key is present in the original tree
but not in the new, it will be dropped in the result.

#### Examples

Let's consider a real-world example. In this scenario, we have a saved
checkpoint with parameters `Dense_0`, `Dense_1`. We want to restore this
checkpoint, with modifications, into a model for training with layers `Dense_0`,
`Dense_1`, `Dense_2`, `Dense_3`.

In this example, we will map original layers 0 and 1 onto the new layers 1 and
2, respectively. We want the new layers 0 and 3 to be initialized randomly, or
with some new values.

The new model may be initialized as a Flax
[TrainState](https://flax.readthedocs.io/en/latest/flax.training.html#train-state),
for example.

```py
params = model.init(
    jax.random.PRNGKey(0), jnp.ones([1, model.input_size]))
new_state = TrainState.create(
    apply_fn=model.apply, params=params, tx=optimizer)
# Restore original state.
original_state = manager.restore(step)
```

```py
 transformations = {
      # NewModel layer 0 is a newly inserted layer, thus use_fallback=True.
      r'(.*)Dense_0(.*)': Transform(use_fallback=True),
      # OriginalModel layer 0 maps to NewModel layer 1
      r'(.*)Dense_1(.*)': Transform(original_key=r'\1Dense_0\2'),
      # OriginalModel layer 1 maps to NewModel layer 2
      r'(.*)Dense_2(.*)': Transform(original_key=r'\1Dense_1\2')
  }  # Note: NewModel layer 3 is newly added.
  restored_state = apply_transformations(original_state, transformations, new_state)
```

Let's unpack what's happening with these transformations.

For layer 0, we want to instruct the function to ignore what's in
`original_state`, and to instead use the value from `new_state`. For this, we
set `use_fallback=True`.

For `Dense_1` and `Dense_2`, we simple provide a regex mapping the original name
of the key (`Dense_0` and `Dense_1`, respectively) to their new values using the
`original_key` field. Note that we can use a regex to match any key containing
the desired pattern, since a PyTree checkpoint will typically represent a single
layer with multiple different arrays, each containing the pattern.

Finally, we can simply omit `Dense_3` from `transformations`, as the `Dense_3`
was provided as a key in `new_state` and the function will simply take the value
from `new_state` and put it in the result.
